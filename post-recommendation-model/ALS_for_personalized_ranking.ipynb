{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iew0zi20ATp-",
        "outputId": "7f7f2698-ab33-4187-e72b-3de2b66031e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended Posts: [3501, 1684, 1409, 3002, 2707, 942, 3895, 2079, 3730, 3994]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import norm\n",
        "from scipy.special import erfinv\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Load Datasets\n",
        "users_df = pd.read_csv(\"users.csv\")\n",
        "posts_df = pd.read_csv(\"posts.csv\")\n",
        "interactions_df = pd.read_csv(\"interactions.csv\")\n",
        "\n",
        "# -------------------------  Personalized Ranking (ALS) -------------------------\n",
        "# Convert implicit feedback into ratings\n",
        "interactions_df[\"rating\"] = interactions_df[\"upvotes\"] * 1 + interactions_df[\"saves\"] * 3 - interactions_df[\"downvotes\"] * 2\n",
        "\n",
        "# Use Surprise SVD for Collaborative Filtering\n",
        "reader = Reader(rating_scale=(-2, 3))  # Ratings range from -2 to 3\n",
        "data = Dataset.load_from_df(interactions_df[[\"user_id\", \"post_id\", \"rating\"]], reader)\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "model = SVD()\n",
        "model.fit(trainset)\n",
        "\n",
        "# Generate ALS-based predictions\n",
        "def get_als_recommendations(user_id, top_n=10):\n",
        "    post_ids = posts_df[\"post_id\"].tolist()\n",
        "    predictions = [(post, model.predict(user_id, post).est) for post in post_ids]\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "    return [post for post, _ in predictions[:top_n]]\n",
        "\n",
        "# ---------------------- Content-Based Filtering (TF-IDF / Similarity) ----------------------\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
        "tfidf_matrix = tfidf.fit_transform(posts_df[\"content\"])\n",
        "\n",
        "# Compute similarity between posts\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Get recommendations based on user interests\n",
        "def get_content_based_recommendations(user_id, top_n=10):\n",
        "    user_interests = users_df[users_df[\"user_id\"] == user_id][\"interests\"].values[0]\n",
        "    user_posts = posts_df[posts_df[\"tags\"].apply(lambda tags: any(i in tags for i in user_interests))]\n",
        "\n",
        "    if user_posts.empty:\n",
        "        return []  # No relevant posts found\n",
        "\n",
        "    sim_scores = cosine_sim[user_posts.index].mean(axis=0)\n",
        "    post_indices = np.argsort(sim_scores)[::-1][:top_n]\n",
        "    return posts_df.iloc[post_indices][\"post_id\"].tolist()\n",
        "\n",
        "# ---------------------- Industry & Work Profile Prioritization ----------------------\n",
        "def get_industry_recommendations(user_id, recommendations, top_n=10):\n",
        "    user_industry = users_df[users_df[\"user_id\"] == user_id][\"industry\"].values[0]\n",
        "    industry_posts = posts_df[posts_df[\"industry\"] == user_industry][\"post_id\"].tolist()\n",
        "\n",
        "    prioritized = [post for post in recommendations if post in industry_posts]\n",
        "    remaining = [post for post in recommendations if post not in industry_posts]\n",
        "\n",
        "    return (prioritized + remaining)[:top_n]\n",
        "\n",
        "# ----------------------  Bayesian Ranking (Wilson Score Interval) ----------------------\n",
        "def wilson_score(upvotes, downvotes, confidence=0.95):\n",
        "    n = upvotes + downvotes\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    z = norm.ppf(1 - (1 - confidence) / 2)\n",
        "    p = upvotes / n\n",
        "    return (p + z**2 / (2 * n) - z * ((p * (1 - p) + z**2 / (4 * n)) / n)**0.5) / (1 + z**2 / n)\n",
        "\n",
        "# Apply Bayesian ranking\n",
        "posts_df[\"wilson_score\"] = posts_df.apply(lambda row: wilson_score(row[\"upvotes\"], row[\"downvotes\"]), axis=1)\n",
        "posts_df = posts_df.sort_values(by=\"wilson_score\", ascending=False)\n",
        "\n",
        "# ----------------------  Final Recommendation Function ----------------------\n",
        "def get_final_recommendations(user_id, top_n=10):\n",
        "    als_recs = get_als_recommendations(user_id, top_n=30)\n",
        "    content_recs = get_content_based_recommendations(user_id, top_n=30)\n",
        "\n",
        "    combined_recs = list(set(als_recs + content_recs))\n",
        "    industry_prioritized_recs = get_industry_recommendations(user_id, combined_recs, top_n=30)\n",
        "\n",
        "    final_recommendations = sorted(industry_prioritized_recs, key=lambda post: posts_df[posts_df[\"post_id\"] == post][\"wilson_score\"].values[0], reverse=True)\n",
        "\n",
        "    return final_recommendations[:top_n]\n",
        "\n",
        "# Test Recommendation\n",
        "user_id = 5\n",
        "recommended_posts = get_final_recommendations(user_id, top_n=10)\n",
        "print(\"Recommended Posts:\", recommended_posts)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq-BVyKfAUqO",
        "outputId": "9f5de878-447d-438c-e6a4-2fba6c6a0c06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.14.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2505210 sha256=c1ec00205efbcacec6a7c30449b72142e9e02fa17a91ebf8401e82040218668b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s_0p5fco/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zObum0kAlF3",
        "outputId": "0bbb3fc8-99b4-43c6-c080-94d0edfc5b08"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy scikit-surprise\n",
        "!pip cache purge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J8J4QPVBFu3",
        "outputId": "0009e271-a225-4b81-d245-d1ac8af09606"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: scikit-surprise 1.1.4\n",
            "Uninstalling scikit-surprise-1.1.4:\n",
            "  Successfully uninstalled scikit-surprise-1.1.4\n",
            "Files removed: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.23.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "_JYuDEIuBjHn",
        "outputId": "1cf4f1b6-6b2f-47e1-9e51-c261a032b112"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.41.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "ff5597f603a748929e949a2cca560330"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --no-cache-dir scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7c2KFiOBpIk",
        "outputId": "a3f4fb40-c00a-4c95-82c2-a88af24baea6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.14.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2505219 sha256=79e941544980c4095f33e845866d8d44d2f7e14b1486b0ec34da1d781c3ab22b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4gze8mwb/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9X77x4QaBvXM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}